Dans nos précédents articles, nous avons vu que l'IA impose de payer à la valeur et de filtrer impitoyablement les fonctionnalités.
Mais une fois le développement lancé, un nouveau danger silencieux émerge : la perte de contrôle sur la "Supply Chain" logicielle.

Jusqu'ici, vous saviez qui codait : des humains, salariés de votre prestataire.
Aujourd'hui, une partie croissante de votre code est générée par des modèles (LLMs), complétée par des agents autonomes, et parfois même testée par d'autres IA.

La question qui fâche : **Si un agent IA introduit une faille de sécurité critique ou copie du code sous licence restrictive, qui est responsable ?**
Votre contrat actuel, rédigé en 2020, n'a probablement aucune réponse à cette question.

#### Le Risque Invisible : La "Shadow AI" dans la Supply Chain

Le rapport **DORA (DevOps Research and Assessment) 2025** est clair : l'IA accélère le flux, mais elle opacifie la provenance.
Le risque pour le DSI n'est plus seulement le bug, c'est la **contamination**.
*   Contamination juridique (Code propriétaire vs Open Source).
*   Contamination sécuritaire (Hallucination de dépendances inexistantes).

Le rôle du partenaire technologique change de dimension. Il ne doit plus seulement fournir des développeurs, il doit garantir la **traçabilité** et la **propreté** du code généré par ses usines IA.

#### Les 3 Nouveaux Modèles d'Engagement (Risk-Based)

On ne peut plus signer un contrat unique. Le niveau d'engagement dépend de votre capacité à contrôler cette nouvelle chaîne de production.

**1. Le Mode "Black Box" (Sérénité)**
*   **Pour qui ?** Les clients qui n'ont pas d'équipe d'ingénierie pointue.
*   **Le Deal :** Le partenaire utilise ses propres IA, ses propres agents. Il vous livre un binaire ou un service.
*   **La Garantie :** Le partenaire porte 100% de la responsabilité juridique et technique. C'est le retour du "Forfait", mais industriel.

**2. Le Mode "Glass Box" (Collaboration)**
*   **Pour qui ?** Les DSI modernes avec une culture DevOps.
*   **Le Deal :** Le partenaire fournit des équipes et les outils IA, mais le code atterrit dans VOTRE CI/CD.
*   **La Garantie :** Responsabilité partagée. Le partenaire garantit la qualité du code (Quality Gates), vous garantissez la sécurité de l'intégration.

**3. Le Mode "Staff Augmentation" (Risque Client)**
*   **Pour qui ?** Les Tech Companies ou DSI Elite.
*   **Le Deal :** Le partenaire fournit des experts qui utilisent VOS outils et VOS IA.
*   **La Garantie :** Vous portez le risque. Le partenaire n'a qu'une obligation de moyens (compétence des humains).

#### La "Quality Gate" comme Juge de Paix

Dans ce monde hybride Humain/IA, la confiance n'est plus interpersonnelle, elle est systémique.
Le cœur du contrat devient la **Quality Gate** (la porte de validation automatique).

Un partenaire sérieux ne doit pas vous vendre "des jours de dev", mais un **taux de passage** de ces portes de qualité :
*   Tests de sécurité (SAST/DAST).
*   Détection de plagiat/licence.
*   Validation de performance.

Si l'IA code vite mais que ça ne passe pas la porte, le compteur ne tourne pas.

#### Conclusion : Exigez un "Certificat de Provenance"

L'ère de l'IA exige une transparence radicale. Ne demandez plus "combien de temps ça a pris ?", demandez "d'où vient ce code et qui l'a validé ?".

Nous avons couvert le Business Model, le Produit et le Delivery. Il reste une dernière brique, souvent la plus précieuse : comment l'IA transforme la gestion de la Connaissance et la formation de vos équipes ? Ce sera notre dernier article.
